# ğŸ“¦ web_csv_relatorio

**Web CSV RelatÃ³rio** Ã© um script em Python que coleta dados via web scraping (por exemplo, preÃ§os ou informaÃ§Ãµes de produtos de um site) e gera automaticamente um arquivo `.csv` contendo essas informaÃ§Ãµes. Ideal para monitoramento, extraÃ§Ã£o de dados e geraÃ§Ã£o rÃ¡pida de relatÃ³rios.

---

## ğŸ› ï¸ Tecnologias

- Python 3.x  
- Bibliotecas utilizadas:
  - `requests`
  - `beautifulsoup4`
  - `selenium` *(opcional, se usar lÃ³gica com navegador)*
  - `pandas`

---

## ğŸ“ Estrutura

```
web_csv_relatorio/
â”œâ”€â”€ coletor_de_precos.py       # Script principal para coleta e exportaÃ§Ã£o CSV
â”œâ”€â”€ produtos_kabum.csv         # Exemplo de resultado gerado apÃ³s execuÃ§Ã£o
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â””â”€â”€ README.md                  # DocumentaÃ§Ã£o do projeto
```

---

## ğŸš€ Como usar

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/eukevinbruno/web_csv_relatorio.git
cd web_csv_relatorio
```

2. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

3. Execute o script:

```bash
python coletor_de_precos.py
```

4. O script criarÃ¡ automaticamente o arquivo `produtos_kabum.csv`.

---

## ğŸ“Š Funcionalidades

- ConfiguraÃ§Ã£o de cabeÃ§alhos (User-Agent) para evitar bloqueios HTTP 403.
- ExtraÃ§Ã£o de dados via `BeautifulSoup` ou `Selenium`.
- OrganizaÃ§Ã£o dos dados em um arquivo CSV.
- Tratamento bÃ¡sico de dados ausentes.

---

## ğŸ”„ Melhorias futuras

- Implementar paginaÃ§Ã£o automÃ¡tica para captar todas as pÃ¡ginas do site.
- Adicionar dados como link do produto, disponibilidade, avaliaÃ§Ã£o, etc.
- Suporte a mÃºltiplos sites alÃ©m do Kabum.
- ExportaÃ§Ã£o opcional para `.xlsx` ou banco de dados.

---

## âœï¸ Autor

**Kevin Bruno** ([@eukevinbruno](https://github.com/eukevinbruno))  
Feito com excelÃªncia e foco na clareza de cÃ³digo e documentaÃ§Ã£o.

---

## âš ï¸ Legal

Projetado para fins educativos. Verifique os Termos de Uso do site alvo antes de coletar dados.
